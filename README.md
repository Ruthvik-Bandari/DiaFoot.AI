# ğŸ¦¶ DiaFoot.AI

**Deep Learning for Diabetic Foot Ulcer Segmentation**

[![Python](https://img.shields.io/badge/Python-3.11-blue.svg)](https://python.org)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-red.svg)](https://pytorch.org)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

A state-of-the-art wound segmentation system using U-Net++ with EfficientNet-B4 encoder, achieving **84.93% IoU** and **91.73% Dice** score on the FUSeg dataset.

![DiaFoot.AI Demo](docs/demo.png)

## ğŸ¯ Performance

| Metric | Score | vs SOTA |
|--------|-------|---------|
| **IoU** | 0.8493 | 97% of DFUC 2022 Winner |
| **Dice** | 0.9173 | 99% of target |
| **Inference** | ~50ms | Real-time capable |

## ğŸ—ï¸ Architecture
```
Input Image (RGB)
      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  CLAHE Enhancement  â”‚  â† Contrast enhancement
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    U-Net++          â”‚
â”‚  EfficientNet-B4    â”‚  â† Pretrained encoder
â”‚    Encoder          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Post-processing    â”‚  â† Remove noise, fill holes
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â†“
Wound Segmentation Mask
```

## ğŸš€ Quick Start

### Installation
```bash
# Clone repository
git clone https://github.com/Ruthvik-Bandari/DiaFoot.AI.git
cd DiaFoot.AI

# Create virtual environment
python3.11 -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

### Download Dataset
```bash
python scripts/download_datasets.py --all
```

### Training
```bash
# Basic training
python scripts/train_simple.py

# Advanced training (Focal Tversky + EMA)
python scripts/train_advanced.py
```

### Inference
```python
from src.inference.optimized_pipeline import load_pipeline
from PIL import Image
import numpy as np

# Load pipeline
pipeline = load_pipeline("outputs/fuseg_simple/best_model.pt")

# Predict
image = np.array(Image.open("wound_image.jpg").convert("RGB"))
result = pipeline.predict(image)

# Get results
mask = result["mask"]                    # Binary segmentation
wound_pct = result["wound_percentage"]   # Wound coverage %
confidence = result["confidence"]        # Model confidence
```

## ğŸ“ Project Structure
```
DiaFoot.AI/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ segmentation.py      # U-Net++ model
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ dataset.py           # Data loading
â”‚   â”‚   â””â”€â”€ augmentation.py      # Augmentations
â”‚   â”œâ”€â”€ training/
â”‚   â”‚   â””â”€â”€ trainer.py           # Training logic
â”‚   â””â”€â”€ inference/
â”‚       â”œâ”€â”€ enhanced_pipeline.py # Full pipeline
â”‚       â””â”€â”€ optimized_pipeline.py# Production pipeline
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ train_simple.py          # Basic training
â”‚   â”œâ”€â”€ train_advanced.py        # Advanced training
â”‚   â”œâ”€â”€ download_datasets.py     # Dataset download
â”‚   â””â”€â”€ test_model.py            # Model testing
â”œâ”€â”€ configs/
â”‚   â””â”€â”€ config.yaml              # Configuration
â”œâ”€â”€ outputs/                     # Trained models
â””â”€â”€ data/                        # Datasets
```

## ğŸ”¬ Technical Details

### Training Configuration

| Parameter | Value |
|-----------|-------|
| Architecture | U-Net++ |
| Encoder | EfficientNet-B4 (ImageNet pretrained) |
| Input Size | 512 Ã— 512 |
| Batch Size | 8 |
| Optimizer | AdamW |
| Learning Rate | 1e-4 (basic), 3e-4 (advanced) |
| Loss | Dice + BCE / Focal Tversky + BCE |
| Epochs | 100-150 |

### Inference Enhancements

- **CLAHE Preprocessing**: Adaptive histogram equalization for contrast
- **Test Time Augmentation**: Horizontal/vertical flips averaged
- **Post-processing**: Small region removal, hole filling, boundary smoothing

## ğŸ“Š Datasets

| Dataset | Images | Used For |
|---------|--------|----------|
| FUSeg 2021 | 1,210 | Training & Validation |
| AZH Wound | 2,849 | Additional training |
| DFUC 2022 | 15,683 | (Requires license) |

## ğŸ“ˆ Results

### Validation Performance
```
Epoch 62: Best Model
â”œâ”€â”€ IoU:  0.8493
â”œâ”€â”€ Dice: 0.9173
â”œâ”€â”€ Train Loss: 0.0486
â””â”€â”€ Val Loss: 0.0630
```

### Test Performance (with optimizations)
```
Average IoU:  0.8097
Average Dice: 0.8915
```

## ğŸ› ï¸ Requirements

- Python 3.11+
- PyTorch 2.0+
- segmentation-models-pytorch
- albumentations
- OpenCV
- NumPy

See `requirements.txt` for full list.

## ğŸ“ Citation

If you use this work, please cite:
```bibtex
@software{diafootai2026,
  author = {Ruthvik Bandari},
  title = {DiaFoot.AI: Deep Learning for Diabetic Foot Ulcer Segmentation},
  year = {2026},
  url = {https://github.com/Ruthvik-Bandari/DiaFoot.AI}
}
```

## ğŸ“„ License

MIT License - see [LICENSE](LICENSE) for details.

## ğŸ™ Acknowledgments

- FUSeg Challenge organizers
- segmentation-models-pytorch library
- Northeastern University AAI6620 Course

---

**Author**: Ruthvik Bandari  
**Course**: AAI6620 Computer Vision, Northeastern University  
**Date**: January 2026
